# üßº Pipeline de Nettoyage de Tweets 

Ce d√©p√¥t fournit un pipeline **modulaire** pour :
- valider un CSV (avec ou sans en-t√™te, texte avec ou sans guillemets),
- d√©tecter automatiquement les colonnes **label** et **tweet**,
- nettoyer le texte (URLs, @mentions, hashtags, ponctuation, espaces, etc.),
- filtrer les doublons et ne garder que la **langue dominante**,
- exporter deux CSV :  
  1) **complet** (toutes colonnes)  
  2) **minimal** (*label + tweet nettoy√©*).

---


## üß© Description des modules

### `file_validation.py`
- V√©rifie la validit√© du fichier CSV (existence, encodage, colonnes, texte).
- Charge les fichiers m√™me **sans en-t√™te** ou **avec des guillemets**.
- G√®re automatiquement les encodages et saute les lignes corrompues.
- Fournit la m√©thode `smart_read_csv()` : lecture robuste et tol√©rante.

### `label_detector.py`
- Trouve automatiquement la **colonne de labels (cible)** √† partir :
  - du nom d‚Äôen-t√™te (`label`, `target`, `sentiment`, ...),
  - des valeurs (0/1/2, positive/negative, etc.),
  - d‚Äôheuristiques (peu de valeurs uniques).

### `tweet_detector.py`
- D√©tecte la **colonne de texte (tweet)** selon :
  - les noms (`text`, `tweet`, `message`, ...),
  - la longueur moyenne,
  - la densit√© d‚Äôespaces,
  - la vari√©t√© des textes.

### `rules.py`
- Contient toutes les **r√®gles de nettoyage textuel** :  
  ```python
  ToLowercase()
  RemoveURLs()
  RemoveMentions()
  RemoveHashtags()
  RemoveRetweetMarker()
  RemovePunctuation()
  NormalizeWhitespace()
  ```
- Ces r√®gles sont combin√©es dans `default_rules()`.

### `tweet_cleaner.py`
- Applique les **r√®gles de texte**, puis les **filtres globaux** :
  - Suppression des doublons,
  - Suppression des tweets dans d'autres langues,
  - Suppression des lignes avec des emojis contradictoires.
- Renvoie un **DataFrame nettoy√©** pr√™t √† √™tre export√©.

### `shipment.py`
- G√®re la **sortie** des donn√©es nettoy√©es :
  ```python
  ShipmentManager(mode="csv").ship(df)
  ShipmentManager(mode="json").ship(df)
  ShipmentManager(mode="dataframe").ship(df)
  ```
- Assure que le CSV minimal contient **label + tweet uniquement**.

### `main.py`
- Orchestration compl√®te :
  1. Validation du CSV  
  2. Chargement avec `smart_read_csv()`  
  3. D√©tection auto des colonnes  
  4. Nettoyage du texte  
  5. Export des r√©sultats

---

## ‚ñ∂Ô∏è Ex√©cution rapide

### Pr√©requis
```bash
pip install csv pandas langdetect charset-normalizer
```

### Lancer le script
```bash
python main.py
```

Le script :
- lit `data/raw/testdata.manual.2009.06.14.csv`
- nettoie les tweets,
- g√©n√®re :  
  - `data/exports/final_cleaned_full.csv` (toutes colonnes)  
  - `data/exports/final_cleaned_min.csv` (label + tweet)

---

## üß† Utilisation du pipeline dans une autre app (GUI, etc.)

### Exemple simple (6 √©tapes)
```python
from file_validation import FileValidation
from column_detection.label_column_detector  import FinalLabelDetector
from column_detection.tweet_column_detector  import FinalTweetDetector, HybridDetector
from tweet_cleaning.tweet_cleaner import TweetCleaner
from export.shipment import  ShipmentManager

# 1Ô∏è‚É£ Charger le CSV
fv = FileValidation("data/raw/mytweets.csv")
assert fv.validate(), "CSV invalide"
df = fv.smart_read_csv()

# 2Ô∏è‚É£ D√©tecter les colonnes
label_idx = FinalLabelDetector().detect(df)
tweet_idx = FinalTweetDetector(fallback_detector=HybridDetector()).detect(df)

# 3Ô∏è‚É£ Nettoyer
cleaner = TweetCleaner()
cleaned_df = cleaner.clean_dataframe(df, tweet_idx=tweet_idx, label_idx=label_idx)

# 4Ô∏è‚É£ Exporter (Full ou Minimal)
ShipmentManager(mode="csv", output_path="data/exports/full.csv").ship(cleaned_df, keep_extra=True, label_idx=label_idx, tweet_idx=tweet_idx)

ShipmentManager(mode="csv", output_path="data/exports/min.csv").ship(cleaned_df, keep_extra=False, label_idx=label_idx, tweet_idx=tweet_idx)

